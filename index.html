<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiayu Lei (雷佳谕)</title>

    <meta name="author" content="Jiayu Lei">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/robot.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:0%;width:60%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                Jiayu Lei (雷佳谕) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                </p>
                <p>I'm a PhD candidate at <a href="https://www.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>, and an intern at <a href="https://shlab.org.cn/pc/home">Shanghai AI Lab</a>,  
                  advised by <a href="https://weidixie.github.io/index.html">Prof. Weidi Xie</a> and <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Prof. Ya Zhang</a>. 
                
                  <!-- I graduated with a bachelor's degree in Information Engineering from the School of Communication Engineering at Xidian University in June 2022. -->
                </p>
                <p>
                  My current research interests include but not limit to Artificial Intelligence for Medical (AI4Med) and Multimodal Perception.
                </p>
                <p>
                  E-mail: misslei@mail.ustc.edu.cn
                </p>

                <p style="text-align:center">
                  <!-- <a href="misslei[at]mail.ustc.edu.cn">Email</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com.hk/citations?user=HVBNwO4AAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ljy19970415">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jiayulei.jpg">
                  <img style="width:100%;max-width:100%;object-fit: cover; " alt="profile photo" src="images/jiayulei.jpg" class="hoverZoomLink">
                </a>
                </td>
              </tr>
               </tbody></table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px;margin-top:0px;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:bottom">
              <h2>Research</h2>        
              <!-- <heading><b></bold>Research</b></heading> -->
              <p>
                <sup>*</sup> denotes equal contribution, and
                <sup>†</sup> denotes corresponding author.
              </p>
            </td></tr>   
             </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:0px;"><tbody>
            <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
              <td style="padding:0px;width:25%;vertical-align:middle">
                <img src="./AutoRG-Brain/resources/model.png" width="320" height="180" style="border-style: none">
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                <a href="https://ljy19970415.github.io/AutoRG-Brain/">
                  <papertitle>AutoRG-Brain: Grounded Report Generation for Brain MRI</papertitle>
                </a>
               <br>
               <strong>Jiayu Lei</strong>,
               <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
               <a href="https://chaoyi-wu.github.io/">Chaoyi Wu</a>,
               <a>Lisong Dai</a>,
                     <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
                     <a href="http://staff.ustc.edu.cn/~yanyongz/">Yanyong Zhang</a>,
                     <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang† </a>,
                     <a href="https://weidixie.github.io/">Weidi Xie†</a>
                     <a>Yuehua Li†</a>
                     <br>
                     <em>Technical Report, 2024.</em><br>
                     AutoRG-Brain is the first regional brain MRI report generation system, that
                     enables comprehensive segmentation of each anomaly region and generation of well-organized narratives, to
                     describe observations in different anatomical region. Additionally, we curate a dataset for grounded report generation, termed as 
                     RadGenome-Brain MRI, with 3,408 multi-modal scans, reports, and ground truth anomaly segmentation masks. 
                     The evaluations demonstrate that AutoRG-Brain generates high-quality report and segmentation, 
                     aiding junior radiologists in aligning their reports with those of senior radiologists.
                   </td>
          </tr>
          <br>
            <br>
            <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                     <td style="padding:0px;width:25%;vertical-align:middle">
                       <img src="images/GPT4V_eval.png" width="290" height="200" style="border-style: none">
                     </td>
                     <td style="padding:10px;width:75%;vertical-align:middle">
                       <a href="https://drive.google.com/file/d/1kPDWgwpv8XlLu5sBuO2mRyylp0PDD6j5/view">
                         <papertitle>Can GPT-4V(ision) Serve Medical Applications ? Case Studies on GPT-4V for Multimodal Medical Diagnosis</papertitle>
                       </a>
                 <br>
                 <a href="https://chaoyi-wu.github.io/">Chaoyi Wu*</a>,
                 <strong>Jiayu Lei*</strong>,
                 <a>Qiaoyu Zheng*</a>,
                 <a href="https://angelakeke.github.io/">Weike Zhao*</a>,
                 <a>Weixiongt Lin*</a>,
                 <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang*</a>,
                 <a>Xiao Zhou*</a>,
                 <a>Ziheng Zhao*</a>,
                       <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
                       <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
                       <a href="https://weidixie.github.io/">Weidi Xie†</a>
                       <br>
                       <em>Technical Report, 2023.</em><br>
                       In this report, we evaluate GPT-4V for multimodal medical diagnosis at case studies, covering 17 human body systems, across 8 clinical imaging modalities. As the cases shown, GPT-4V is still far from clinical usage.
                      </td>
              </tr>
  
         
                 
          </tbody></table>
          <br>
          <br>
          <br>
          <br>
          <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=h4YAqAN-BtgTi1jCWzvBvvs7JxONKNSiMa8xorgrfDk&co=3d95d3&cmn=f71111&cmo=ffc253'></script> -->
  </body>
</html>
